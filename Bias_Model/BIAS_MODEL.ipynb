{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package twitter_samples to\n",
      "[nltk_data]     /home/edco17/nltk_data...\n",
      "[nltk_data]   Package twitter_samples is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/edco17/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Model Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import keras\n",
    "#from keras.utils import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Flatten, Dense, SimpleRNN, LSTM, GRU, Dropout\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from seaborn import heatmap\n",
    "#from gensim.models.keyedvectors import KeyedVectors\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk\n",
    "from os import getcwd\n",
    "#import gensim\n",
    "#from gensim.test.utils import common_texts\n",
    "import re\n",
    "import string\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from keras.models import load_model\n",
    "from sklearn.metrics import classification_report\n",
    "import pickle\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from unicodedata import normalize\n",
    "import re\n",
    "import xgboost as xgb\n",
    "\n",
    "def process_tweet(tweet):\n",
    "    \"\"\"Process tweet function.\n",
    "    Input:\n",
    "        tweet: a string containing a tweet\n",
    "    Output:\n",
    "        tweets_clean: a list of words containing the processed tweet\n",
    "\n",
    "    \"\"\"\n",
    "    stemmer = PorterStemmer()\n",
    "    stopwords_english = stopwords.words('spanish')\n",
    "    # remove stock market tickers like $GE\n",
    "    tweet = re.sub(r'\\$\\w*', '', tweet)\n",
    "    # remove old style retweet text \"RT\"\n",
    "    tweet = re.sub(r'^RT[\\s]+', '', tweet)\n",
    "    # remove hyperlinks\n",
    "    tweet = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', tweet)\n",
    "    # remove hashtags\n",
    "    # only removing the hash # sign from the word\n",
    "    tweet = re.sub(r'#', '', tweet)\n",
    "    # tokenize tweets\n",
    "    tokenizer = TweetTokenizer(preserve_case=False, strip_handles=True,\n",
    "                               reduce_len=True)\n",
    "    tweet_tokens = tokenizer.tokenize(tweet)\n",
    "\n",
    "    tweets_clean = []\n",
    "    for word in tweet_tokens:\n",
    "        if (word not in stopwords_english and  # remove stopwords\n",
    "                word not in string.punctuation):  # remove punctuation\n",
    "            # tweets_clean.append(word)\n",
    "            stem_word = stemmer.stem(word)  # stemming word\n",
    "            tweets_clean.append(stem_word)\n",
    "\n",
    "    return tweets_clean\n",
    "\n",
    "\n",
    "def build_freqs(tweets, ys):\n",
    "    \"\"\"Build frequencies.\n",
    "    Input:\n",
    "        tweets: a list of tweets\n",
    "        ys: an m x 1 array with the sentiment label of each tweet\n",
    "            (either 0 or 1)\n",
    "    Output:\n",
    "        freqs: a dictionary mapping each (word, sentiment) pair to its\n",
    "        frequency\n",
    "    \"\"\"\n",
    "    # Convert np array to list since zip needs an iterable.\n",
    "    # The squeeze is necessary or the list ends up with one element.\n",
    "    # Also note that this is just a NOP if ys is already a list.\n",
    "    yslist = np.squeeze(ys).tolist()\n",
    "\n",
    "    # Start with an empty dictionary and populate it by looping over all tweets\n",
    "    # and over all processed words in each tweet.\n",
    "    freqs = {}\n",
    "    for y, tweet in zip(yslist, tweets):\n",
    "        for word in process_tweet(tweet):\n",
    "            pair = (word, y)\n",
    "            if pair in freqs:\n",
    "                freqs[pair] += 1\n",
    "            else:\n",
    "                freqs[pair] = 1\n",
    "\n",
    "    return freqs\n",
    "\n",
    "nltk.download('twitter_samples')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "\n",
    "def limpieza_str(s):\n",
    "  s = re.sub(r\"([^n\\u0300-\\u036f]|n(?!\\u0303(?![\\u0300-\\u036f])))[\\u0300-\\u036f]+\", r\"\\1\", \n",
    "          normalize( \"NFD\", s), 0, re.I)\n",
    "  s = normalize( 'NFC', s).lower().replace('\\n','')\n",
    "  return(s.lstrip().rstrip())\n",
    "\n",
    "def mrep(s):\n",
    "  repl = {',':'.',';':'.','-':'.',':':'.'}\n",
    "  for k, i in repl.items():\n",
    "    s=s.replace(k,i)\n",
    "  return s\n",
    "\n",
    "def word_gender(word):\n",
    "    if word.upper()[-1] == 'O':\n",
    "        gender = 'M'\n",
    "    elif word.upper()[-1] == 'A':\n",
    "        gender = 'F'\n",
    "    else:\n",
    "        gender = 'N'\n",
    "    return gender\n",
    "\n",
    "\n",
    "def bias_model_prediction(url):\n",
    "    \n",
    "    ## url data\n",
    "    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 6.1; WOW64; rv:50.0) Gecko/20100101 Firefox/50.0'}\n",
    "    r = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(r.text)\n",
    "    \n",
    "    ## extracciÃ³n\n",
    "    busq = ['p','h1','h2','h3','h4','h5','h6','menu','title','dt','hr','li','ol','ul','caption','tr']\n",
    "    Textos = {finds: soup.find_all(finds) for finds in busq if len(soup.find_all(finds))!=0}\n",
    "    textos = {keys:[limpieza_str(ele.text) for ele in Textos[keys]] for keys in Textos.keys()}\n",
    "    # Si no se puede usar limpieza_str\n",
    "    # textos = {keys:[ele.text.strip().lower() for ele in Textos[keys]] for keys in Textos.keys()}\n",
    "\n",
    "    frases = [item for k, sublist in textos.items() for item in sublist]\n",
    "    spliteo = [mrep(f).split('.') for f in frases]\n",
    "    # Que tenga al menos 3 palabras\n",
    "    frases_p = list(set([item.strip().replace('  ',' ') for sublist in spliteo for item in sublist if item.strip().count(' ')>2]))\n",
    "    \n",
    "    ## array preprocess\n",
    "    X_raw=np.array(frases_p)\n",
    "    preprocess_list = np.array([process_tweet(x) for x in X_raw])\n",
    "    \n",
    "    ## gender list\n",
    "    gender_list = []\n",
    "    for frase in X_raw:\n",
    "        for word in frase:\n",
    "            gender_list.append(word_gender(word))\n",
    "    masc, fem = (pd.Series(gender_list).value_counts(1)['F'], pd.Series(gender_list).value_counts(1)['M'])\n",
    "    \n",
    "    if masc > fem:\n",
    "        incli = 'MASCULINO'\n",
    "    else:\n",
    "        incli = 'FEMENINO'\n",
    "    \n",
    "    # Word to vector\n",
    "    maxlen = 100 #max number of word\n",
    "    max_words = 20000 #considers the first 20000 words\n",
    "    \n",
    "\n",
    "    ## TOKENIZER\n",
    "    #myfile = drive.CreateFile({'id': '1pOJ_u8rHxndklavjBgUSWzlLuP2aWoKO'})\n",
    "    #myfile.GetContentFile('tokenizer_bbva3.pickle')\n",
    "    file = open('/home/edco17/Escritorio/hackaton2022/tokenizer_bbva3.pickle', 'rb')\n",
    "    tokenizer = pickle.load(file)\n",
    "    sequences = tokenizer.texts_to_sequences(preprocess_list)\n",
    "    \n",
    "    # Word idctionary\n",
    "    word_index = tokenizer.word_index\n",
    "    data = pad_sequences(sequences, maxlen=maxlen)\n",
    "    \n",
    "    ## model\n",
    "    #myfile = drive.CreateFile({'id': '1FxlOTsTLdyW6evDzUGQLyjIgwNebg6M6'})\n",
    "    #myfile.GetContentFile('model_Hackathon_22.h5')\n",
    "    model = xgb.Booster()\n",
    "    model.load_model(\"/home/edco17/Escritorio/hackaton2022/xg_model_Hackathon.txt\")\n",
    "    #model = load_model('/home/edco17/Escritorio/hackaton2022/xg_model_Hackathon.h5')\n",
    "    #model = load_model('/home/edco17/Escritorio/hackaton2022/model_light_Hackathon.h5')\n",
    "\n",
    "    ## prediction\n",
    "    #prediction = model.predict(xgb.DMatrix(data))\n",
    "    prediction = (model.predict(xgb.DMatrix(data))>0.43).astype('int')\n",
    "    df_pred = pd.DataFrame(frases_p, columns = ['full_text'])\n",
    "    df_pred['prediction'] = prediction\n",
    "    \n",
    "    ## JSON \n",
    "    resultado = {}\n",
    "    resultado['porcentaje_sesgo'] = prediction.mean()\n",
    "    resultado['proporcion_masculina'] = masc\n",
    "    resultado['proporcion_femenina'] = fem\n",
    "    resultado['inclinacion'] = incli\n",
    "    \n",
    "    ## model return\n",
    "    return resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[03:29:14] WARNING: ../src/learner.cc:851: Loading model from XGBoost < 1.0.0, consider saving it again for improved compatibility\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-120-4b68fe157efc>:146: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  preprocess_list = np.array([process_tweet(x) for x in X_raw])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'porcentaje_sesgo': 0.09009009009009009,\n",
       " 'proporcion_masculina': 0.09320732614649127,\n",
       " 'proporcion_femenina': 0.07837457060993178,\n",
       " 'inclinacion': 'MASCULINO'}"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias_model_prediction('https://es.wikipedia.org/wiki/Ludwig_van_Beethoven')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
